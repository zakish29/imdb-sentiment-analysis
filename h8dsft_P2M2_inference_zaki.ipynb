{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Load Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import string\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Library Pre-Processing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "  \n",
    "imdb_sentiment = load_model('imdb_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    lstemmer = LancasterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    additional_stopwords = ['film', 'movie', 'actor', 'actress', 'director', 'plot', 'character', 'review', 'rating', 'storyline', 'story', 'series', 'time', 'since', 'film', 'people', 'scene']\n",
    "    stpwds_eng = list(set(stopwords.words('english')))\n",
    "    for i in additional_stopwords:\n",
    "        stpwds_eng.append(i)\n",
    "    text = re.sub(r'#[A-Za-z0-9_]+', '', text)\n",
    "    text = re.sub(\"@[A-Za-z0-9_.]+\",\"\", text) \n",
    "    text = re.sub('\\w*(\\w)\\1{2,}\\w','\\1', text)\n",
    "    text = re.sub('\\b[ha]*(?:ha|ha)[ha]*\\b|\\b[lol]*(?:lol|lol)[lol]*\\b|lmfao|lmao','', text)\n",
    "    text = re.sub('\\\\n','', text)\n",
    "    text = text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    text = re.sub(r'\\b(I|we|they|she|he)\\b', '', text) # replace pronouns with empty string \n",
    "    text = text.strip() \n",
    "    text = re.sub('www.\\S+|http\\S+','', text)\n",
    "    tokens = word_tokenize(text) # Mendeteksi token pada kalimat\n",
    "    text = ' '.join([word for word in tokens if word not in stpwds_eng])\n",
    "    text = lstemmer.stem(text)  # stemming\n",
    "    text = lemmatizer.lemmatize(text, pos=\"v\")  # lemmatizing\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it surely a good movie. me and my girlfriend s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  it surely a good movie. me and my girlfriend s..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create New Data \n",
    "\n",
    "data_inf = {\n",
    "    'review' : 'it surely a good movie. me and my girlfriend said she loved it'                                \n",
    "}\n",
    "\n",
    "data_inf = pd.DataFrame([data_inf])\n",
    "data_inf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'surely good girlfriend said loved'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inf['review'] = data_inf['review'].apply(lambda x: text_process(x))\n",
    "data_inf['review'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 376ms/step\n",
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "# Prediksi jenis tweet\n",
    "\n",
    "y_inf_pred = np.argmax(imdb_sentiment.predict(data_inf['review']), axis=1)\n",
    "\n",
    "# Membuat fungsi untuk return result prediksi\n",
    "if y_inf_pred[0] == 0:\n",
    "    result = 'Negative'\n",
    "elif y_inf_pred[0] == 1:\n",
    "    result = 'Neutral'\n",
    "else:\n",
    "    result = 'Positive'\n",
    "\n",
    "# Print Result\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
